name: CI (Test & Validate)

on:
  push:
    branches: [main]
  pull_request:

permissions:
  contents: read

jobs:
  test-and-validate:
    runs-on: ubuntu-latest
    steps:
      # ------------------------------------------------------------------
      # Checkout & Python setup
      # ------------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ------------------------------------------------------------------
      # Quality gates & Unit tests
      # ------------------------------------------------------------------
      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV

      - name: Run unit tests + coverage
        # Using fake credentials for testing only
        env:
          KAFKA_BOOTSTRAP: localhost:9092
          KAFKA_API_KEY: fake_key
          KAFKA_API_SECRET: fake_secret
          KAFKA_TEAM: myteam
          AWS_ACCESS_KEY_ID: fake_access_key
          AWS_SECRET_ACCESS_KEY: fake_secret_key
          AWS_REGION: us-east-2
        run: |
          mkdir -p reports
          pytest --maxfail=1 --disable-warnings \
            --cov=. \
            --cov-report=term-missing \
            --cov-report=xml:reports/coverage.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: reports/coverage.xml
          flags: unittests
          fail_ci_if_error: false # Don't block pipeline if codecov fails
          verbose: true

      # ------------------------------------------------------------------
      # Smoke tests (Offline eval + drift detection)
      # ------------------------------------------------------------------
      - name: Verify data files
        run: |
          echo "Verifying dataset contents:"
          ls -lh data/ml1m_prepared || echo "!! Dataset missing!"

      - name: Run offline evaluation (ItemCF)
        run: python experiments/ml1m_baselines/train_itemcf.py

      # Drift quality gate: fails if PSI exceeds threshold
      - name: Run drift detection
        id: drift
        continue-on-error: false
        run: |
          echo "Checking for data drift..."
          python -m recommender.drift --threshold 0.25

      - name: CI Summary
        run: |
          echo "âœ… CI Tests Passed" >> $GITHUB_STEP_SUMMARY